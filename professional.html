<!DOCTYPE HTML> 
<html>
<head>
    <link rel="stylesheet" type="text/css" href="assets/css/professional.css">
</head>

<body>
    <div id = "page-container">
        <div id = "navbar">
            <div class = "navbar-item" id = "home">
                <a href = "index.html">Home</a>
            </div>
            <div class = "navbar-item" id = "about">
                <a href = "about.html">About</a>
            </div>
            <div class = "navbar-item" id = "professional">
                <a href = "professional.html">Professional</a>
            </div>
            <div class = "navbar-item" id = "education">
                <a href = "education.html">Education</a>
            </div>
        </div>
        <div id = "projects-container" class = "cont">
            <div class = "header">
                <div id = "projects-title" class = "prof-title">
                    Projects 
                </div>
            </div>
            <div id = "projects-content-container">
                <div id = "deep" class = "projects-content">
                    <div id = "deep-title" class =  "header2">
                        <div class = "cont-title">Deep Learning For Cancer Detection</div>
                    </div>
                    <div class = "prof-content-container">
                        <div id = "deep-content"  class = "prof-content">
                            <p>At CalHacks 2018, I lead a team of 3 in developing a supervised deep learning algorithm for classifiying images of cellular tissue
                                as cancerous or benign. I initially utilized convolutional neural networks in Tensorflow Keras to train over 4000 images.
                                Not getting the results that I wanted, I deduced that one or more of the following problems had occured: the number of epochs that I used was too low (the training did not converge), I did not have enough
                                data to capture the variance among the images, or that my network needed more layers. My laptop did not have the necessary computing power for me to increase the epochs and layers in the limited
                                time that I had. After researching for some time, I discovered a solution to solve both of my problems. First, I uploaded the cell images to Google Cloud. I then utilized Google's pretrained networks
                                through Google's AutoML API to increase the accuracy and speed of my training. This resulted in an algorithm with over 90% accuracy, as can be seen in the confusion matrix displayed in the picture to the right.
                            </p>
                        </div>
                        <div id = "deep-photo" class = "prof-content"><img src = "assets/img/deep.png" height = "300"></div>
                    </div>
                </div>
        
                <div id = "unsupervised" class = "projects-content">
                    <div id = "unsupervised-title" class = "header2">
                        <div class = "cont-title">Unsupervised Learning of 1000 Reuters Articles</div>
                    </div>
                    <div class = "prof-content-container">
                        <div id = "unsupervised-content" class = "prof-content" >
                            <p>For this project, I gathered 1000 Reuters articles across 5 different topics. My goal was to see if I could correctly seperate the articles into their respective topics based on the unique words in their articles. I parsed through all of the articles and gathered a set of all of the unique words in the articles. I then made a matrix with the rows as article names and the columns as unique words. The entries of the matrix contained a 1 if the word was present in the corresponding article and a 0 otherwise. I then calculated the covariance of all the article pairs and placed that into a matrix after normalizing the entries. I then ran principal component analysis on the covariance matrix to project the data to its first two principal components. Before clustering the data, I used the elbow method to determine the optimal number of clusters for the data. Although I already knew the data should have corresponded to five clusters, I wanted to make sure that the data reflected that based on my analysis. The elbow curve properly predicted that 5 clusters would be optimal. I then clustered the PCA data using k means clustering through pythons sklearn package, which properly seperated the data into 5 clusters.  </p>
                        </div>
                        <div id = "ul-photo-container">
                            <div id = "ul-photo" class = "prof-content"><img src = "assets/img/nlp.png" height = "250"></div>
                            <div id = "elbow-photo" class = "prof-content"><img src = "assets/img/elbow.png" height = "250"></div>
                        </div>
                    </div>
                </div>

               
                    <div id = "car" class = "projects-content">
                        <div id = "car-title" class = "header2">
                            <div class = "cont-title">EE16B: Voice Controlled Robot Car</div>
                        </div>
                         <div class = "prof-content-container">
                            <div id = "car-content" class = "prof-content" >
                                <p>Here is a video of my group’s completed project for our EE16B: Designing Information Devices and Systems II course! We spent countless hours implementing the micboard, bandpass filter, biasing circuits, wheel encoders, wheel motors, and much more in addition to writing a lot of code along the way to allow our car to be controllable. Our car was powered by two 9V batteries and an MSP-EXP430F launchpad. My favorite part of the project was implementing the voice control. To do this, we gathered about 30 voice recorded samples each for 4 words that were very colloquially dissimilar to maximize the variance among the data. The data was then placed into a matrix with the data for each word belonging to its own row. We used a supervised machine learning algorithm based on classification to carry out the voice control. We performed principal component analysis on the training data to project the data onto the first two principal components, as they captured most of the variance in the data. We then used K-means clustering with 4 centroids to group the words with the highest covariance. Our algorithm predicted which word each input belonged to by determining which cluster had the minimum euclidean distance to the input data.</p>
                            </div>
                            <div id = "car-video" class = "prof-content" >
                                <iframe src="https://www.linkedin.com/embed/feed/update/urn:li:ugcPost:6480030578484875264?compact=1" height="284" width="504" frameborder="0" allowfullscreen=""></iframe>
                            </div>
                        </div>
                </div>
            </div>
        </div>
        <div id = "we-container" class = "cont" >
            <div class = "header">
                <div id = "work-experience-title" class = "prof-title">
                    Work Experience
                </div>
            </div>
            <div id = "we-content-container">
                
                <div id = "code-mettle" class = "projects-content">
                    <div id = "code-mettle-title" class =  "header2">
                        <div class = "cont-title">CodeMettle</div>
                    </div>
                    <div class = "prof-content-container">
                        <div id = "code-mettle-content" class = "prof-content">
                            Currently working at CodeMettle in Sandy Springs, Georgia as an Associate Software engineer. Through my work at CodeMettle, I developed a Scala based troubleshooting tool to diagnose common issues with installation of CodeMettle’s core product. More recently, I've been working on developing customer tailored network management software for the U.S. State Department. 
                        </div>
                          <div id = "cm-photo" class = "prof-content"><img src = "assets/img/codemettle.png" height = "250"></div>
                    </div>
                </div>
                <div id = "academic-intern" class = "projects-content">
                    <div id =academic-intern-title" class = "header2">
                        <div class = "cont-title">Academic Intern (August 2018 - December 2018)
                        </div>
                    </div>

                    <div class = "prof-content-container">
                        <div id = "academic-intern-content" class = "prof-content" >
                            Worked as a volunteer teaching assistant on the CS61B (Data Structures) course staff. Helped students develop effective problem-solving skills, resulting in increased comprehension of data structures.
                        </div>
                         <div id = "ai-photo" class = "prof-content"><img src = "assets/img/data_structures.jpeg" height = "250"></div>
                    </div>
                </div>
              
                <div id = "pta" class = "projects-content">
                    <div id = "pta-title" class = "header2">
                        <div class = "cont-title">Professional Tutors of America (November 2015 - August 2017)
                        </div>
                    </div>
                    <div class = "prof-content-container">
                        <div id = "pta-content" class = "prof-content" >
                            Advanced student understanding of math and chemistry principles.
                        </div>
                        <div id = "pta-photo" class = "prof-content"><img src = "assets/img/pta.png" height = "250"></div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</body>

</html>
